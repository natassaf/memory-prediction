{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4954bd8d",
   "metadata": {},
   "source": [
    "# Execution time prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32a5cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "941004bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data, features_to_use):\n",
    "    data['binary_name'] = data['binary_name'].str.split('/').str[-1]\n",
    "    features = data.loc[:, features_to_use]\n",
    "    features.iloc[:,0] = features.iloc[:,0].apply(lambda x: abs(hash(x)))\n",
    "    memory_target = data.iloc[:, -2]\n",
    "    time_target = data.iloc[:, -1]\n",
    "    return features, memory_target, time_target\n",
    "\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv('data/training_data.csv')\n",
    "features_to_use = [\n",
    "    'binary_size_bytes','data_section_size_bytes','function_count',\n",
    "    'high_complexity_functions','linear_memory_bytes','instance_count',\n",
    "    'resource_count','is_ml_workload','model_file_size','request_payload_size'\n",
    "]\n",
    "df_shuffled = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "features, memory_target, time_target = data_preprocessing(df_shuffled, features_to_use)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1ed0d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary_name</th>\n",
       "      <th>binary_size_bytes</th>\n",
       "      <th>data_section_size_bytes</th>\n",
       "      <th>import_count</th>\n",
       "      <th>export_count</th>\n",
       "      <th>function_count</th>\n",
       "      <th>global_variable_count</th>\n",
       "      <th>type_definition_count</th>\n",
       "      <th>instance_count</th>\n",
       "      <th>resource_count</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_local_variables_per_function</th>\n",
       "      <th>high_complexity_functions</th>\n",
       "      <th>linear_memory_bytes</th>\n",
       "      <th>total_function_references</th>\n",
       "      <th>is_ml_workload</th>\n",
       "      <th>request_payload_size</th>\n",
       "      <th>model_file_size</th>\n",
       "      <th>payload</th>\n",
       "      <th>memory_kb</th>\n",
       "      <th>task_duration_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_classification_resnet_onnx_batch.cwasm</td>\n",
       "      <td>1230768</td>\n",
       "      <td>22</td>\n",
       "      <td>107</td>\n",
       "      <td>211</td>\n",
       "      <td>985</td>\n",
       "      <td>4</td>\n",
       "      <td>1326</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.3684</td>\n",
       "      <td>51</td>\n",
       "      <td>1114112</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>297742</td>\n",
       "      <td>46782752</td>\n",
       "      <td>297742</td>\n",
       "      <td>216992</td>\n",
       "      <td>1.424655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>matrix_transpose.cwasm</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>53</td>\n",
       "      <td>102</td>\n",
       "      <td>584</td>\n",
       "      <td>4</td>\n",
       "      <td>693</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.3864</td>\n",
       "      <td>21</td>\n",
       "      <td>1114112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1834603</td>\n",
       "      <td>0</td>\n",
       "      <td>1834603</td>\n",
       "      <td>51040</td>\n",
       "      <td>0.315899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_classification_resnet_onnx_batch.cwasm</td>\n",
       "      <td>1230768</td>\n",
       "      <td>22</td>\n",
       "      <td>107</td>\n",
       "      <td>211</td>\n",
       "      <td>985</td>\n",
       "      <td>4</td>\n",
       "      <td>1326</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.3684</td>\n",
       "      <td>51</td>\n",
       "      <td>1114112</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1790942</td>\n",
       "      <td>46782752</td>\n",
       "      <td>1790942</td>\n",
       "      <td>225968</td>\n",
       "      <td>1.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fibonacci_optimized.cwasm</td>\n",
       "      <td>689248</td>\n",
       "      <td>38</td>\n",
       "      <td>58</td>\n",
       "      <td>110</td>\n",
       "      <td>606</td>\n",
       "      <td>4</td>\n",
       "      <td>714</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4129</td>\n",
       "      <td>22</td>\n",
       "      <td>1114112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>25888</td>\n",
       "      <td>0.228653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>matrix_multiplication_component.cwasm</td>\n",
       "      <td>672200</td>\n",
       "      <td>38</td>\n",
       "      <td>53</td>\n",
       "      <td>102</td>\n",
       "      <td>585</td>\n",
       "      <td>4</td>\n",
       "      <td>694</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4189</td>\n",
       "      <td>21</td>\n",
       "      <td>1114112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1337532</td>\n",
       "      <td>0</td>\n",
       "      <td>1337532</td>\n",
       "      <td>39040</td>\n",
       "      <td>0.337054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    binary_name  binary_size_bytes  \\\n",
       "0  image_classification_resnet_onnx_batch.cwasm            1230768   \n",
       "1                        matrix_transpose.cwasm                  0   \n",
       "2  image_classification_resnet_onnx_batch.cwasm            1230768   \n",
       "3                     fibonacci_optimized.cwasm             689248   \n",
       "4         matrix_multiplication_component.cwasm             672200   \n",
       "\n",
       "   data_section_size_bytes  import_count  export_count  function_count  \\\n",
       "0                       22           107           211             985   \n",
       "1                       38            53           102             584   \n",
       "2                       22           107           211             985   \n",
       "3                       38            58           110             606   \n",
       "4                       38            53           102             585   \n",
       "\n",
       "   global_variable_count  type_definition_count  instance_count  \\\n",
       "0                      4                   1326              41   \n",
       "1                      4                    693              23   \n",
       "2                      4                   1326              41   \n",
       "3                      4                    714              25   \n",
       "4                      4                    694              23   \n",
       "\n",
       "   resource_count  ...  avg_local_variables_per_function  \\\n",
       "0               0  ...                            5.3684   \n",
       "1               0  ...                            4.3864   \n",
       "2               0  ...                            5.3684   \n",
       "3               0  ...                            4.4129   \n",
       "4               0  ...                            4.4189   \n",
       "\n",
       "   high_complexity_functions  linear_memory_bytes  total_function_references  \\\n",
       "0                         51              1114112                          0   \n",
       "1                         21              1114112                          0   \n",
       "2                         51              1114112                          0   \n",
       "3                         22              1114112                          0   \n",
       "4                         21              1114112                          0   \n",
       "\n",
       "   is_ml_workload  request_payload_size  model_file_size  payload  memory_kb  \\\n",
       "0               1                297742         46782752   297742     216992   \n",
       "1               0               1834603                0  1834603      51040   \n",
       "2               1               1790942         46782752  1790942     225968   \n",
       "3               0                     9                0       30      25888   \n",
       "4               0               1337532                0  1337532      39040   \n",
       "\n",
       "    task_duration_sec  \n",
       "0            1.424655  \n",
       "1            0.315899  \n",
       "2            1.630000  \n",
       "3            0.228653  \n",
       "4            0.337054  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebf3358",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6229a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_denormalized(y_true, y_pred_normalized, target_scaler):    \n",
    "    # Denormalize predictions and true values\n",
    "    y_true_denorm = target_scaler.inverse_transform(y_true.reshape(-1, 1)).ravel()\n",
    "    y_pred_denorm = target_scaler.inverse_transform(y_pred_normalized.reshape(-1, 1)).ravel()\n",
    "    \n",
    "    # Calculate denormalized RMSE\n",
    "    mse_denorm = mean_squared_error(y_true_denorm, y_pred_denorm)\n",
    "    denormalized_rmse = np.sqrt(mse_denorm)\n",
    "    return denormalized_rmse\n",
    "\n",
    "def rmse(y_true, y_pred_normalized):    \n",
    "    # Calculate denormalized RMSE\n",
    "    mse_denorm = mean_squared_error(y_true, y_pred_normalized)\n",
    "    denormalized_rmse = np.sqrt(mse_denorm)\n",
    "    return denormalized_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32401822",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb90e3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1039, 10)\n",
      "Target scaler mean: 1.6361656818700674\n",
      "Target scaler scale: 7.386948263760952\n"
     ]
    }
   ],
   "source": [
    "# Fit scalers on training data (correct approach)\n",
    "features_scaler = StandardScaler().fit(features.to_numpy())\n",
    "target_scaler = StandardScaler().fit(time_target.to_numpy().reshape(-1, 1))\n",
    "\n",
    "# Transform training data\n",
    "X = features_scaler.transform(features.to_numpy())\n",
    "y = target_scaler.transform(time_target.to_numpy().reshape(-1, 1)).ravel()\n",
    "\n",
    "print(\"Training data shape:\", X.shape)\n",
    "print(\"Target scaler mean:\", target_scaler.mean_[0])\n",
    "print(\"Target scaler scale:\", target_scaler.scale_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "270d26c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD model initialized\n",
      "SGDRegressor(learning_rate='adaptive', random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# Initialize SGD model\n",
    "sgd_model = SGDRegressor(\n",
    "    loss='squared_error',\n",
    "    max_iter=1000,\n",
    "    learning_rate='adaptive',\n",
    "    eta0=0.01,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"SGD model initialized\")\n",
    "print(sgd_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb464c68",
   "metadata": {},
   "source": [
    "### Dynamic training experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9890e205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 100 training samples: \n",
      " RMSE: 0.9923179277010701, Denormalized RMSE: 7.330201193130286\n",
      "After 200 training samples: \n",
      " RMSE: 0.9643526836907568, Denormalized RMSE: 7.123623382442651\n",
      "After 300 training samples: \n",
      " RMSE: 0.9863975022619893, Denormalized RMSE: 7.286467316712342\n",
      "After 400 training samples: \n",
      " RMSE: 1.0402876990828975, Denormalized RMSE: 7.6845514125522865\n",
      "After 500 training samples: \n",
      " RMSE: 1.125380924976538, Denormalized RMSE: 8.313130669825133\n",
      "After 600 training samples: \n",
      " RMSE: 1.0981428198193337, Denormalized RMSE: 8.111924196225983\n",
      "After 700 training samples: \n",
      " RMSE: 1.1733495815932966, Denormalized RMSE: 8.667472654535242\n",
      "After 800 training samples: \n",
      " RMSE: 1.1364372661345434, Denormalized RMSE: 8.394803289945807\n",
      "After 900 training samples: \n",
      " RMSE: 1.10981052364153, Denormalized RMSE: 8.198112920717435\n",
      "After 1000 training samples: \n",
      " RMSE: 1.7379615671444568, Denormalized RMSE: 12.838232180901006\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, X, y, epochs=1):\n",
    "    \"\"\"\n",
    "    Train the model on the given batch of rows with partial fit\n",
    "    Args:\n",
    "        model: SGDRegressor model\n",
    "        X: Array of feature rows (2D array)\n",
    "        y: Array of target values (1D array)\n",
    "    \"\"\"\n",
    "    # Use partial_fit for online learning\n",
    "    for _ in range(epochs):\n",
    "        model.partial_fit(X, y)\n",
    "    return model\n",
    "\n",
    "def predict_next_rows(model, rows):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the rows producing both an RMSE normalized and denormalized\n",
    "    \"\"\"\n",
    "    if len(rows) == 0:\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    # Get true values for these rows\n",
    "    y_true = y[index+1:index+1+len(rows)]\n",
    "    \n",
    "    # Predict on normalized data\n",
    "    y_pred_normalized = model.predict(rows)\n",
    "    \n",
    "    # Calculate normalized RMSE\n",
    "    mse_normalized = mean_squared_error(y_true, y_pred_normalized)\n",
    "    normalized_rmse = np.sqrt(mse_normalized)\n",
    "    \n",
    "    # Denormalize predictions and true values\n",
    "    y_true_denorm = target_scaler.inverse_transform(y_true.reshape(-1, 1)).ravel()\n",
    "    y_pred_denorm = target_scaler.inverse_transform(y_pred_normalized.reshape(-1, 1)).ravel()\n",
    "    \n",
    "    # Calculate denormalized RMSE\n",
    "    mse_denorm = mean_squared_error(y_true_denorm, y_pred_denorm)\n",
    "    denormalized_rmse = np.sqrt(mse_denorm)\n",
    "    \n",
    "    return normalized_rmse, denormalized_rmse\n",
    "\n",
    "counter = 0\n",
    "for index in range(1, len(X)):\n",
    "    sgd_model = train_model(sgd_model, X[0: index], y[0: index])\n",
    "    counter += 1\n",
    "    rmse, denormalized_rmse=predict_next_rows(sgd_model,X[index+1:])\n",
    "    if counter % 100 == 0:\n",
    "        print(f\"After {counter} training samples: \\n RMSE: {rmse}, Denormalized RMSE: {denormalized_rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd35ed",
   "metadata": {},
   "source": [
    "## Cross-Validation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53747214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num training samples 831\n",
      "num validation samples 208\n",
      "Fold 1: MSE=25.86, RMSE=5.08\n",
      "num training samples 831\n",
      "num validation samples 208\n",
      "Fold 2: MSE=117.48, RMSE=10.84\n",
      "num training samples 831\n",
      "num validation samples 208\n",
      "Fold 3: MSE=45.64, RMSE=6.76\n",
      "num training samples 831\n",
      "num validation samples 208\n",
      "Fold 4: MSE=44.56, RMSE=6.68\n",
      "num training samples 832\n",
      "num validation samples 207\n",
      "Fold 5: MSE=37.59, RMSE=6.13\n",
      "\n",
      "Cross-Validation Results:\n",
      "Mean MSE: 54.22 ± 32.40\n",
      "Mean MAE: 7.10 ± 1.96\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "cv_rmse_scores = []\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X)):\n",
    "    print(\"num training samples\", len(train_idx))\n",
    "    print(\"num validation samples\", len(val_idx))\n",
    "    X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "    y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Train model\n",
    "    model_fold = SGDRegressor(\n",
    "        loss='squared_error',\n",
    "        max_iter=1000,\n",
    "        learning_rate='adaptive',\n",
    "        eta0=0.01,\n",
    "        random_state=42\n",
    ")\n",
    "    \n",
    "    # Use partial_fit for online learning (multiple passes)\n",
    "    n_passes = 10  # Number of epochs\n",
    "    for epoch in range(n_passes):\n",
    "        model_fold.partial_fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    y_pred_fold = model_fold.predict(X_val_fold)\n",
    "    \n",
    "    mse = mean_squared_error(y_val_fold, y_pred_fold)\n",
    "    mae = mean_absolute_error(y_val_fold, y_pred_fold)\n",
    "    \n",
    "    # Inverse transform to get actual values\n",
    "    y_val_actual = target_scaler.inverse_transform(y_val_fold.reshape(-1, 1)).ravel()\n",
    "    y_pred_actual = target_scaler.inverse_transform(y_pred_fold.reshape(-1, 1)).ravel()\n",
    "    \n",
    "    mse_actual = mean_squared_error(y_val_actual, y_pred_actual)\n",
    "    rmse_actual = rmse_denormalized(y_val_fold, y_pred_fold, target_scaler)\n",
    "    cv_scores.append(mse_actual)\n",
    "    cv_rmse_scores.append(rmse_actual)\n",
    "    \n",
    "    print(f\"Fold {fold + 1}: MSE={mse_actual:.2f}, RMSE={rmse_actual:.2f}\")\n",
    "\n",
    "print(f\"\\nCross-Validation Results:\")\n",
    "print(f\"Mean MSE: {np.mean(cv_scores):.2f} ± {np.std(cv_scores):.2f}\")\n",
    "print(f\"Mean MAE: {np.mean(cv_rmse_scores):.2f} ± {np.std(cv_rmse_scores):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a73fa",
   "metadata": {},
   "source": [
    "## Final Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dacda7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final SGD model on all training data...\n",
      "Training completed with 10 epochs!\n",
      "Model training completed!\n",
      "\n",
      "Training Results:\n",
      "MSE: 50.43\n",
      "RMSE: 7.10\n"
     ]
    }
   ],
   "source": [
    "# Train final model on all training data\n",
    "print(\"Training final SGD model on all training data...\")\n",
    "# Train using partial_fit for online learning\n",
    "n_passes = 10  # Number of epochs\n",
    "for epoch in range(n_passes):\n",
    "    sgd_model.partial_fit(X, y)\n",
    "print(f\"Training completed with {n_passes} epochs!\")\n",
    "print(\"Model training completed!\")\n",
    "\n",
    "# Evaluate on training data\n",
    "y_train_pred = sgd_model.predict(X)\n",
    "\n",
    "# Inverse transform to get actual values\n",
    "y_train_actual = target_scaler.inverse_transform(y.reshape(-1, 1)).ravel()\n",
    "y_train_pred_actual = target_scaler.inverse_transform(y_train_pred.reshape(-1, 1)).ravel()\n",
    "\n",
    "train_mse = mean_squared_error(y_train_actual, y_train_pred_actual)\n",
    "rmse = rmse_denormalized(y, y_train_pred, target_scaler   )\n",
    "\n",
    "print(f\"\\nTraining Results:\")\n",
    "print(f\"MSE: {train_mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71154f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a35c77",
   "metadata": {},
   "source": [
    "## Save Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86bef44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_model/scaler_y_time.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and scalers\n",
    "import os\n",
    "os.makedirs('model', exist_ok=True)\n",
    "\n",
    "joblib.dump(sgd_model, 'time_model/time_model_sgd.pkl')\n",
    "joblib.dump(features_scaler, 'time_model/scaler_x_time.pkl')\n",
    "joblib.dump(target_scaler, 'time_model/scaler_y_time.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3a4261",
   "metadata": {},
   "source": [
    "# Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c0d406d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data shape: (150, 10)\n",
      "Testing scaler mean: 1.6361656818700674\n",
      "Testing scaler scale: 7.386948263760952\n",
      "Testing Results:\n",
      "MSE: 48.86\n",
      "RMSE: 0.95\n",
      "RMSE Denormalized: 6.99\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load a model\n",
    "model = joblib.load('time_model/time_model_sgd.pkl')\n",
    "\n",
    "# Load scalers\n",
    "scaler_x = joblib.load('time_model/scaler_x_time.pkl')\n",
    "scaler_y = joblib.load('time_model/scaler_y_time.pkl')\n",
    "\n",
    "data = pd.read_csv('data/testing_data.csv')\n",
    "features_to_use = [\n",
    "    'binary_size_bytes','data_section_size_bytes','function_count',\n",
    "    'high_complexity_functions','linear_memory_bytes','instance_count',\n",
    "    'resource_count','is_ml_workload','model_file_size','request_payload_size'\n",
    "]\n",
    "df_shuffled = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "features, memory_target, time_target = data_preprocessing(df_shuffled, features_to_use)\n",
    "\n",
    "# Transform test data\n",
    "X = scaler_x.transform(features.to_numpy())\n",
    "y = scaler_y.transform(time_target.to_numpy().reshape(-1, 1)).ravel()\n",
    "\n",
    "print(\"Testing data shape:\", X.shape)\n",
    "print(\"Testing scaler mean:\", scaler_y.mean_[0])\n",
    "print(\"Testing scaler scale:\", scaler_y.scale_[0])\n",
    "\n",
    "# Evaluate on training data\n",
    "y_train_pred = model.predict(X)\n",
    "\n",
    "# Inverse transform to get actual values\n",
    "y_train_actual = scaler_y.inverse_transform(y.reshape(-1, 1)).ravel()\n",
    "y_train_pred_actual = scaler_y.inverse_transform(y_train_pred.reshape(-1, 1)).ravel()\n",
    "\n",
    "test_mse = mean_squared_error(y_train_actual, y_train_pred_actual)\n",
    "rmse = rmse(y, y_train_pred)\n",
    "rmse_denormalized = rmse_denormalized(y, y_train_pred, target_scaler)\n",
    "\n",
    "print(f\"Testing Results:\")\n",
    "print(f\"MSE: {test_mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"RMSE Denormalized: {rmse_denormalized:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
