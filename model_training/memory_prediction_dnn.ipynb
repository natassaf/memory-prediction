{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/athanasiapharmake/workspace/memory-prediction/model_training/model_venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Optimized TensorFlow imports for faster loading\n",
        "import os\n",
        "import joblib\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TensorFlow warnings\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Disable GPU for faster imports\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # Disable optimizations that slow imports\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Import matplotlib only when needed for plotting\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# Optimized TensorFlow imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Import only what's needed from sklearn\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_preprocessing(data):\n",
        "    data['binary_name'] = data['binary_name'].str.split('/').str[-1]\n",
        "    features = data.iloc[:, :-1]\n",
        "    features.iloc[:,0] = features.iloc[:,0].apply(lambda x: abs(hash(x)))\n",
        "    memory_target = data.iloc[:, -2]\n",
        "    time_target = data.iloc[:, -1]\n",
        "    return features, memory_target, time_target\n",
        "\n",
        "def data_preprocessing_old(data):\n",
        "    data['binary_name'] = data['binary_name'].str.split('/').str[-1]\n",
        "    features = data.iloc[:, :-1]\n",
        "    features.iloc[:,0] = features.iloc[:,0].apply(lambda x: abs(hash(x)))\n",
        "\n",
        "    target = data.iloc[:, -1]\n",
        "    return features, target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape: (1039, 21)\n",
            "Target scaler mean: 70735.3532242541\n",
            "Target scaler scale: 63897.676863767854\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load and preprocess data\n",
        "data = pd.read_csv('data/training_data.csv')\n",
        "features, memory_target, time_target = data_preprocessing(data)\n",
        "\n",
        "# Fit scalers on training data (correct approach)\n",
        "features_scaler = StandardScaler().fit(features.to_numpy())\n",
        "target_scaler = StandardScaler().fit(memory_target.to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Transform training data\n",
        "X = features_scaler.transform(features.to_numpy())\n",
        "y = target_scaler.transform(memory_target.to_numpy().reshape(-1, 1))\n",
        "\n",
        "print(\"Training data shape:\", X.shape)\n",
        "print(\"Target scaler mean:\", target_scaler.mean_[0])\n",
        "print(\"Target scaler scale:\", target_scaler.scale_[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def build_model_32_32():\n",
        "    model = Sequential([\n",
        "        Dense(32, activation='relu', input_shape=(X.shape[1],)),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)  # output layer for regression\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_model_32_32_32():\n",
        "    model = Sequential([\n",
        "        Dense(32, activation='relu', input_shape=(X.shape[1],)),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)  # output layer for regression\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_model_64_64():\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1)  # output layer for regression\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "def train_model(model):\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    mse_scores_normalized = []\n",
        "    mse_scores_denormalized = []\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_train, X_val = X[train_idx], X[val_idx]\n",
        "        y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "        model.fit(X_train, y_train, epochs=30, batch_size=32, verbose=0)\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        y_pred = model.predict(X_val).flatten()\n",
        "        mse = mean_squared_error(y_val, y_pred)\n",
        "        mse_scores_normalized.append(mse)\n",
        "\n",
        "        y_original = target_scaler.inverse_transform(y_val.reshape(-1, 1)).flatten()\n",
        "        y_pred_original = target_scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
        "        mse = mean_squared_error(y_original, y_pred_original)\n",
        "        mse_scores_denormalized.append(mse)\n",
        "\n",
        "    rmse_normalized = np.sqrt(mse_scores_normalized)\n",
        "    rmse_denormalized = np.sqrt(mse_scores_denormalized)\n",
        "\n",
        "\n",
        "    print(\"MSE scores per fold normalized:\", mse_scores_normalized)\n",
        "    print(\"Average MSE normalized:\", np.mean(mse_scores_normalized))\n",
        "    print(\"Average RMSE normalized:\", np.mean(np.sqrt(rmse_normalized)))\n",
        "\n",
        "    print(\"MSE scores per fold denormalized:\", mse_scores_denormalized)\n",
        "    print(\"Average MSE denormalized:\", np.mean(mse_scores_denormalized))\n",
        "    print(\"Average RMSE denormalized:\", np.mean(np.sqrt(rmse_denormalized)))\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "MSE scores per fold normalized: [0.0009477299459771471, 0.00027440147571780604, 0.0002512071505748038, 0.00025805398463400113, 0.00021089908371480743]\n",
            "Average MSE normalized: 0.00038845832812371315\n",
            "Average RMSE normalized: 0.13546204780898727\n",
            "MSE scores per fold denormalized: [3869500.613999293, 1120356.630235452, 1025656.1397250616, 1053609.966537934, 861085.5268348289]\n",
            "Average MSE denormalized: 1586041.775466514\n",
            "Average RMSE denormalized: 34.24208320434995\n"
          ]
        }
      ],
      "source": [
        "modeL_32_32 = build_model_32_32()\n",
        "modeL_32_32 = train_model(modeL_32_32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 1ms/step\n",
            "MSE scores per fold normalized: [0.0007488197519334065, 0.0003492657275182174, 0.00043118573551030614, 0.0001696568661155276, 0.0001444574494359142]\n",
            "Average MSE normalized: 0.0003686771061026743\n",
            "Average RMSE normalized: 0.1339978256278141\n",
            "MSE scores per fold denormalized: [3057370.0879063974, 1426019.6726177656, 1760498.2387144016, 692691.6316181513, 589805.6560459413]\n",
            "Average MSE denormalized: 1505277.0573805314\n",
            "Average RMSE denormalized: 33.87195255474952\n"
          ]
        }
      ],
      "source": [
        "modeL_32_32_32 = build_model_32_32_32()\n",
        "modeL_32_32_32 = train_model(modeL_32_32_32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 1ms/step\n",
            "MSE scores per fold normalized: [0.0003943105392221005, 0.0004114478049461689, 0.00010141128547494544, 6.439411282995394e-05, 3.6663754209227614e-05]\n",
            "Average MSE normalized: 0.00020164549933647928\n",
            "Average RMSE normalized: 0.11021672657826931\n",
            "MSE scores per fold denormalized: [1609934.9474880327, 1679911.5495133768, 414055.2181651409, 262915.17635530693, 149695.55386241968]\n",
            "Average MSE denormalized: 823302.4890768554\n",
            "Average RMSE denormalized: 27.86058627430888\n"
          ]
        }
      ],
      "source": [
        "modeL_64_64 = build_model_64_64()\n",
        "modeL_64_64 = train_model(modeL_64_64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data = pd.read_csv('data/testing_data.csv')\n",
        "X_test, y_test_memory, y_test_time = data_preprocessing(test_data)\n",
        "\n",
        "X_test_normalized = features_scaler.transform(X_test.to_numpy())\n",
        "y_test_normalized = target_scaler.transform(y_test_memory.to_numpy().reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 2ms/step\n",
            "Test RMSE (normalized): 0.020499\n"
          ]
        }
      ],
      "source": [
        "# Train final model on full training data\n",
        "final_model = build_model_64_64()\n",
        "final_model.fit(X, y, epochs=30, batch_size=32, verbose=0)\n",
        "\n",
        "# Make predictions on test set\n",
        "y_test_pred_normalized = final_model.predict(X_test_normalized).flatten()\n",
        "\n",
        "# Calculate normalized RMSE\n",
        "mse_normalized = mean_squared_error(y_test_normalized, y_test_pred_normalized)\n",
        "rmse_normalized = np.sqrt(mse_normalized)\n",
        "\n",
        "print(f\"Test RMSE (normalized): {rmse_normalized:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test RMSE (normalized): 0.020499\n",
            "Test RMSE (denormalized): 1309.815920\n",
            "\n",
            "=== DIAGNOSTIC INFORMATION ===\n",
            "Target scaler mean: 70735.35\n",
            "Target scaler scale: 63897.68\n",
            "Expected denormalized RMSE ≈ 1309.82\n",
            "\n",
            "Training target range: 25040.00 to 233504.00\n",
            "Test target range: 25056.00 to 233600.00\n",
            "\n",
            "Training target mean: 70735.35\n",
            "Test target mean: 78808.64\n",
            "Test data outside training range: True\n"
          ]
        }
      ],
      "source": [
        "# Calculate denormalized RMSE and diagnose the issue\n",
        "y_test_original = target_scaler.inverse_transform(y_test_normalized.reshape(-1, 1)).flatten()\n",
        "y_test_pred_original = target_scaler.inverse_transform(y_test_pred_normalized.reshape(-1, 1)).flatten()\n",
        "\n",
        "mse_denormalized = mean_squared_error(y_test_original, y_test_pred_original)\n",
        "rmse_denormalized = np.sqrt(mse_denormalized)\n",
        "\n",
        "print(f\"Test RMSE (normalized): {rmse_normalized:.6f}\")\n",
        "print(f\"Test RMSE (denormalized): {rmse_denormalized:.6f}\")\n",
        "\n",
        "# Diagnostic information\n",
        "print(f\"\\n=== DIAGNOSTIC INFORMATION ===\")\n",
        "print(f\"Target scaler mean: {target_scaler.mean_[0]:.2f}\")\n",
        "print(f\"Target scaler scale: {target_scaler.scale_[0]:.2f}\")\n",
        "print(f\"Expected denormalized RMSE ≈ {rmse_normalized * target_scaler.scale_[0]:.2f}\")\n",
        "\n",
        "print(f\"\\nTraining target range: {memory_target.min():.2f} to {memory_target.max():.2f}\")\n",
        "print(f\"Test target range: {y_test_memory.min():.2f} to {y_test_memory.max():.2f}\")\n",
        "\n",
        "print(f\"\\nTraining target mean: {memory_target.mean():.2f}\")\n",
        "print(f\"Test target mean: {y_test_memory.mean():.2f}\")\n",
        "\n",
        "# Check if test data is outside training range\n",
        "test_out_of_range = (y_test_memory.min() < memory_target.min()) or (y_test_memory.max() > memory_target.max())\n",
        "print(f\"Test data outside training range: {test_out_of_range}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test RMSE (normalized): 0.020499\n",
        "Test RMSE (denormalized): 1309.815920\n",
        "\n",
        "Training average RMSE normalized: 0.11021672657826931\n",
        "Training Average RMSE denormalized: 27.86058627430888"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_model(model, x_scaler, y_scaler):    \n",
        "    model.save(\"memory_model/memory_model.keras\")\n",
        "    joblib.dump(x_scaler, \"memory_model/scaler_x.pkl\")\n",
        "    joblib.dump(y_scaler, \"memory_model/scaler_y.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_model(final_model, features_scaler, target_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "model_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
